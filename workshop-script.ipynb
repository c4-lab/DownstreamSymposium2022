{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the environment is not set up properly, uncomment and run the following:\n",
    "# !pip install --user spacy==3.1.6\n",
    "# !pip install --user coreferee\n",
    "# !python -m spacy download en_core_web_lg\n",
    "# !python -m coreferee install en\n",
    "# !pip install tensorflow\n",
    "# !pip install negspacy\n",
    "# !pip install spacy-langdetect\n",
    "# !pip install sklearn\n",
    "# !pip install seaborn\n",
    "# !pip install torch\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a7b52",
   "metadata": {},
   "source": [
    "Let's load all the packages we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.manifold import TSNE\n",
    "from seaborn import scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbedb7a",
   "metadata": {},
   "source": [
    "Let's load the dataset for the demo! it contains twitter posts we collected related to climate change. Those tweets are not cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/demo_test_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8808893",
   "metadata": {},
   "source": [
    "Let take a look at the top five tweets from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6313fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in df['full_tweet_text'].loc[:5]:\n",
    "    print(tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffdf0a",
   "metadata": {},
   "source": [
    "They look kind of messy! let first clean them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./src/preprocessing.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e06365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['clean_text'] = df['full_tweet_text'].apply(clean_tweet, args=(False,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9571d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in df['clean_text'].loc[:5]:\n",
    "    print(tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1e5fb",
   "metadata": {},
   "source": [
    "Looks better! let's try it on SpaCy's dependency parser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "#add_to_pipe(nlp)\n",
    "#txt = \"The MSM would have you to believe that evidence is overwhelming that manmade climate change is modest and benign, and CO2 emissions are beneficial.\"\n",
    "#txt = \"World can likely capture and store enough carbon dioxide to meet climate targets but there are many other factors in mitigating climate change\"\n",
    "txt = df['clean_text'].loc[0]\n",
    "doc = nlp(txt)\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f661c",
   "metadata": {},
   "source": [
    "We have created a component that extracts beliefs from a tweet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c6e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"./src/belief_extraction_spacy.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4337e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "add_to_pipe(nlp)\n",
    "\n",
    "def process_text(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    subjects = []\n",
    "    for b in doc._.beliefs:\n",
    "        cleaned = b.clean_belief()\n",
    "        subject = b.clean_subject()\n",
    "        if len(cleaned) > 0:\n",
    "            result +=cleaned\n",
    "            subjects+=subject\n",
    "    return result,subjects\n",
    "\n",
    "df['beliefs'] = df['clean_text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458852b7",
   "metadata": {},
   "source": [
    "Let's look at one of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['beliefs'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e0f4a",
   "metadata": {},
   "source": [
    "For each tweet, the belief extraction code will extract subjects and beliefs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfe62c",
   "metadata": {},
   "source": [
    "Next, let's write all beliefs into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_dict = {}\n",
    "belief_dict['belief'] = []\n",
    "belief_dict['subject'] = []\n",
    "\n",
    "for r in df['beliefs']:\n",
    "    if len(r[0]) != 0:\n",
    "        for b in r[0]:\n",
    "            belief, subject = b[0], b[1]\n",
    "            belief_dict['belief'].append(belief.lower())\n",
    "            belief_dict['subject'].append(subject.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_df = pd.DataFrame(belief_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75212f81",
   "metadata": {},
   "source": [
    "Now we have belief texts and the corresponding subject for that belief! in order to quantify beliefs to create the belief landscape, we need to generate sentence embedding for each belief:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a796ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./src/embedding/embeddings_climatebert.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134585",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed_list(belief_df['belief'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14962c10",
   "metadata": {},
   "source": [
    "Done! let's look at the belief embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619482ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aafb18a",
   "metadata": {},
   "source": [
    "Let's put them into a dataframe with belief and subject texts so we know the corresponding subject for a embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.concat([pd.DataFrame(belief_dict), pd.DataFrame(embeddings)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae891b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d89f02",
   "metadata": {},
   "source": [
    "As you may have noticed, each embedding is 768 dimensional. It is a disaster to visualize them! so we will need to do dimension reduction with t-sne: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4381aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#First, run PCA to reduce this to a manageable number of dimensions\n",
    "\n",
    "pca_reduction = PCA(n_components=30)\n",
    "pca_results = pca_reduction.fit_transform(embeddings_df.drop(['belief', 'subject'], axis = 1).values)\n",
    "pca_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79732d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_embedded = TSNE(n_components=2, learning_rate='auto',  init='random', perplexity=50, n_iter=3000).\\\n",
    "    fit_transform(pca_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935056d8",
   "metadata": {},
   "source": [
    "We want to visualize those belief embeddings using a two-dimensional graph, so we choose 2 components for the t-sne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e417a32",
   "metadata": {},
   "source": [
    "We want to locate a subject that we are interested. We want to better understand how it is located in the belief landscape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168b92d",
   "metadata": {},
   "source": [
    "That doesn't give us a lot of information. Let's look at all the subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\",\".join(embeddings_df['subject'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446d503",
   "metadata": {},
   "source": [
    "We may observe that there are a lot of subject related to \"climate\", e.g. \"climate policy\". We will look at how those subjects locates in the belief landscape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db6ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatterplot(x=tsne_embedded[:, 0], y=tsne_embedded[:, 1], hue = embeddings_df['subject'].str.contains(\"climate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ab2a1",
   "metadata": {},
   "source": [
    "There is a pretty tight cluster here, so let's filter those and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = -12\n",
    "xmax = -5\n",
    "ymin = -7.5\n",
    "ymax = -2.4\n",
    "\n",
    "tsne_df = pd.DataFrame(tsne_embedded,columns=[\"x\",\"y\"])\n",
    "embeddings_df['climate'] = embeddings_df['subject'].str.contains(\"climate\")\n",
    "embeddings_df['hits'] = (tsne_df['x'] > xmin) & (tsne_df['x'] < xmax) & (tsne_df['y'] > ymin) & (tsne_df['y'] < ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bd88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(x=tsne_df['x'], y=tsne_df['y'], hue = embeddings_df['hits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d79397",
   "metadata": {},
   "source": [
    "Now we can look at various cuts of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets about climate in the identified region\n",
    "embeddings_df[(embeddings_df['climate']==True) & (embeddings_df['hits']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-climate tweets in the identified region\n",
    "embeddings_df[(embeddings_df['climate']==False) & (embeddings_df['hits']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate tweets outside of the identified region\n",
    "embeddings_df[(embeddings_df['climate']==True) & (embeddings_df['hits']==False)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
